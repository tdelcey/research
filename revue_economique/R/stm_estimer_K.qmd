## Choix de K et du prétraitement

À partir de six représentations du corpus, nous cherchons à estimer le nombre de thématiques de notre modèle $K$. Pour déterminer $K$, nous entraînons une série de modèles avec $K \in \{10, 20, ..., 70\}$. Nous estimons un modèle pour chaque valeur de $K$ (nombre de thématiques) et pour chaque valeur de $N$ (nombre de représentation du corpus selon le filtrage des mots), soit 42 modèles.

Le _structural topic model_ est implémenté dans `R` dans le package `stm` [@roberts2013structural]. L'ensemble des informations relatives à cette implémentation est disponible sur le [site web](http://www.structuraltopicmodel.com/) dédié. Pour une exploration avancée, l'ensemble du code `R` est disponible sur le [GitHub](https://github.com/bstewart/stm/tree/master/R). Une série d'articles des auteurs présentent le modèle. @roberts2016model est la présentation la plus complète pour une exploration avancée de l'inférence bayésienne utilisée.  

 
```{r}
#| echo: TRUE
#| eval: FALSE 
#| label: "Search K"

#' K evaluation 
#' to start the session open
 
library(stm)
library(furrr)
library(tidyverse)

corpora_in_stm <- readRDS(here::here(private_data_path, "corpora_in_stm.rds"))


#prepare furrr parallélisation
# 
# nb_cores <- availableCores() / 2 
# plan(multisession, workers = nb_cores)

#run multiple topic models 

seed <- 123

many_stm <- tibble::tibble(
  K = seq(10, 70, by = 10),
  preprocessing = list(names(corpora_in_stm))) %>% 
  tidyr::unnest(cols = c(K, preprocessing)) %>% 
  dplyr::mutate(st_models = map2(
    K,
    preprocessing,
    ~ {
      # run stm 
      stm::stm(
        documents = corpora_in_stm[[.y]]$documents,
        vocab = corpora_in_stm[[.y]]$vocab,
        data = corpora_in_stm[[.y]]$meta,
        prevalence = as.formula("~has_female + is_varia + s(year)"),
        K = .x,
        init.type = "Spectral",
        max.em.its = 800,
        verbose = FALSE,
        seed = seed
      )
      
    },
    .progress = TRUE,
    .options = furrr_options(seed = seed)
  ))

saveRDS(many_stm, here::here(private_data_path, "many_stm.rds"), compress = TRUE)

```

Nous avons utilisé deux métriques : la _FREX_ et la cohérence sémantique pour chacune de ces combinaisons.

La cohérence sémantique mesure la similarité entre les mots d'un thème [@mimno2011optimizing]. Similaire à la PMI dans l'esprit, la cohérence sémantique mesure la probabilité de voir deux mots ensemble dans un thème à partir d'une liste de $M$ mots les plus probables par thématique. La _FREX_ (ou FREquent EXclusivity) est une mesure qui partage l'esprit de la célèbre mesure tf-idf et vise à évaluer l'importance d'un mot $w$ dans un thème $k$, en tenant compte à la fois de sa fréquence et de son exclusivité [@bischof2012summarizing] Nous utilisons la bibliothèque `stm` pour estimer ces métriques, respectivement les fonctions `stm::semanticCoherence` et `stm::exclusivity` avec un parametrage par defaut. Ces résultats indiquent que, quel que soit le prétraitement, un nombre de thèmes de 50 semble être un bon compromis entre la cohérence sémantique et la _FREX_.


```{r}
#| echo: TRUE
#| eval: FALSE 
#| label: "compute metrics"

many_stm <- readRDS(here::here(private_data_path, "many_stm.rds"))
corpora_in_stm <- readRDS(here(private_data_path, "corpora_in_stm.rds"))

# estimate exclusivity and coherence 

setDT(many_stm)

# unnest corpus_in_stm by K 
many_stm[, corpus_in_stm := corpora_in_stm, by = K]

# many_stm[, heldout := future_map(corpus_in_stm, ~ make.heldout(.x$documents, .x$vocab))]
many_stm[, exclusivity := map(st_models, exclusivity)]
many_stm[, semantic_coherence := map2(st_models, corpus_in_stm, ~ semanticCoherence(.x, .y$documents))]

evaluation_result <- many_stm[, .(
  K,
  preprocessing, 
  # heldout = mean(unlist(map(eval_heldout, "expected.heldout"))),
  # residual = mean(unlist(map(residual, "dispersion"))),
  semantic_coherence = map_dbl(semantic_coherence, mean),
  exclusivity = map_dbl(exclusivity, mean)
  # lbound
)]

```
