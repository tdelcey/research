Notre jeu de données est composé de quatre tables :

-   Une table des **métadonnées**. Chaque ligne est un document qui possède un identifiant unique, `id`. Cet identifiant est soit l'identifiant Persée, soit l'identifiant Cairn. Certaines lignes partagent le même `id` car quelques documents dans la base de données originale de la *Revue Économique* correspondent à une même notice bibliographique dans Persée ou Cairn. Une URL est disponible pour chaque document pour consulter la notice Persée ou Cairn en ligne.
-   Une table des **auteurs** associés à ces documents. Chaque ligne correspond à un auteur d'un document et nous leur avons attribué un identifiant unique `id_authors`. Chaque auteur est associé à ses documents par un identifiant que nous avons créé, `id_document`. Les auteurs sont identifiés par leur nom, prénom, genre. Pour les documents archivés par Persée, nous avons également enrichi la base de données avec les informations issues d'[IdRef](https://www.idref.fr/), une base de données qui recense les informations sur les auteurs de l'enseignement et de la recherche en France.
-   Une table des **éditeurs**. Chaque ligne correspond à un éditeur et une position institutionnelle au sein d'une université et/ou de la *Revue Economique* . Si une personne change d'universités ou de position dans le comité éditoriale, plusieurs lignes lui sont attribuées. La personne est identifiée par son nom, prénom, genre, institution, discipline et position au sein de la Revue Economique ainsi que les dates d'entrées et de sorties. 
-   Une table avec les **textes entiers**. Malheureusement, nous ne pouvons pas partager les textes entiers pour des raisons de droits d’auteur. Le reste des données est consultable et téléchargeable dans les tableaux interactifs ci-dessous de la section ou directement la page [GitHub](https://github.com/tdelcey/research/revue_economique) du package de replication.

## Sources 

Nous avons utilisé trois sources principales pour la construction de notre base de données. La première source est un document interne à la revue économique qui répertorie les documents publiés dans la _Revue Économique_ entre 1950 et 2019. Ce document comprend plusieurs métadonnées des documents que nous avons exploitées : les titres, les auteurs, leur genre, l'année de publication, les numéros spéciaux, le type de document (note de lecture, article, etc.).

Nous avons enrichi cette base de données avec deux autres sources, les deux bibliothèques numériques [Persée](https://www.persee.fr/), qui archive la revue économique entre 1950 et 2000, et [Cairn](https://www.cairn.info/), qui couvre la période de 2001 à aujourd'hui. Nous avons notamment utilisé les API de ces deux bibliothèques pour récupérer les résumés des articles ([https://oai.cairn.info/](https://oai.cairn.info/) et [https://www.persee.fr/entrepot-oai](https://www.persee.fr/entrepot-oai)). Nous avons également eu accès, après demande, aux textes entiers. Ces derniers ne sont malheureusement pas open data. Cairn nous a également donné accès aux citations entrantes et sortantes pour chaque document.

La table des éditeurs a été construite par nos soins. Nous avons recoupé les informations sur Cairn, Persée, Jstor et d'autres entrepôts de la recherche en France comme [https://data.bnf.fr/](https://data.bnf.fr/), [https://www.sudoc.abes.fr/](https://www.sudoc.abes.fr/) ou [https://theses.fr/?domaine=theses](https://theses.fr/).


```{r}
#| echo: TRUE
#| warning: FALSE

documents <- read_xlsx(here(clean_corpus_path, "re_metadata_1950_2023.xlsx"),
                       col_types = "text") %>% unique
authors <- read_xlsx(here(clean_corpus_path, "re_authors_1950_2023.xlsx"),
                     col_types = "text") %>% unique
editors <- read_xlsx(here(clean_corpus_path, "re_editors.xlsx"),
                     col_types = "text") %>% unique
```


## Nettoyage

L'algorithme ci-dessous vise à identifier des doublons par le biais de la stratégie suivante :

- Les documents sont groupés par le premier auteur du document ;
- Pour chaque groupe, nous calculons la distance _Optimal String Alignment_ (OSA) des titres. La mesure OSA calcule le nombre d'opérations (insertions, deletions, substitutions, and adjacent character transpositions) nécessaires pour rendre parfaitement identiques deux chaînes de caractères. Cette méthode est implémentée sur `R` via le package [`stringdist`](https://CRAN.R-project.org/package=stringdist) [@van2014stringdist].
- Nous identifions et fusionnons les doublons en fonction de deux seuils : la distance OSA et la distance normalisée (distance OSA divisée par le produit des longueurs des deux titres).

```{r}
#| echo: TRUE
#| eval: FALSE
#| warning: FALSE
#| message: FALSE

# first delete forthcoming article that are duplicates 

# remove duplicates and save 

documents <- documents %>% 
  filter(!issue == "Forthcoming") 

# select author information used in find_duplicate()

authors_info_to_join <- authors %>%
  select(id_document, authors)

# join
documents_with_authors <- documents %>%
  left_join(authors_info_to_join, by = c("id" = "id_document"))

# create metadata for stm
data_to_check <- documents_with_authors %>%
  filter(type %in% c("varia", "numéro spécial", "")) %>%
  # nest author
  group_by(id) %>%
  mutate(authors_list = list(authors)) %>%
  mutate(authors = first(authors)) %>%
  # remove non unique line
  unique %>%
  # harmonize authors
  mutate(authors = str_remove_all(authors, "[[:punct:]]"),
         authors = str_to_lower(authors),
         authors = str_squish(authors)) %>%
  #remove special cases, regular chroniques
  filter(!title %in%
           c("Chronique de la pensée économique en Italie",
             "Commentaires",
             "La situation économique",
             "Avant-propos",
             "Introduction",
             "introduction"))

duplicates <- find_duplicates(data_dt = data_to_check,
                                          threshold_distance = 6,
                                          threshold_normalization = 0.1,
                                          workers = 4)

duplicates <- duplicates %>%
  group_by(id) %>%
  mutate(duplicates = list(c(id, id_2)),
         duplicates = map(duplicates, ~ .x %>% sort()))

# Add duplicates to the main metadata table
documents <- documents %>%
  left_join(duplicates %>%
              select(id, duplicates)) %>%
  mutate(duplicates = ifelse(duplicates == "NULL", NA_character_, duplicates))

duplicates_to_keep <- documents %>%
  filter(!is.na(duplicates)) %>%
  # sort
  unique %>%
  group_by(duplicates) %>%
  arrange(!is.na(abstract_fr),
          # Prioritize rows where abstract_fr is not NA
          as.numeric(issue),
          # Prioritize numeric issues (NA if not numeric)
          issue != "Forthcoming",
          # Ensure "Forthcoming" is deprioritized
          .by_group = TRUE) %>%
  slice(1) %>%  # Keep only the first row within each group
  ungroup() %>%
  unique()

documents <- documents %>%
  filter(is.na(duplicates)) %>%
  bind_rows(duplicates_to_keep)

# maj authors data removing lines with duplicates

id_to_keep <- documents$id

authors <- authors %>%
  filter(id_document %in% id_to_keep)

saveRDS(documents, here(clean_corpus_path, "documents_no_duplicates.rds"))
saveRDS(authors, here(clean_corpus_path, "authors_no_duplicates.rds"))
```


## Tables 

```{r}
#| echo: TRUE 
#| warning: FALSE

documents <- readRDS(here(clean_corpus_path, "documents_no_duplicates.rds")) 

authors <- readRDS(here(clean_corpus_path, "authors_no_duplicates.rds"))

editors <- read_xlsx(here(clean_corpus_path, "re_editors.xlsx"),
                     col_types = "text") %>% unique
```

::: {.panel-tabset}

### Documents 

```{r}
#| echo: TRUE  
#| warning: FALSE
#| tbl-cap: "Table des documents"

documents <- documents %>% 
  # trunc abstracts for table lisibility  
  mutate(abstract_fr = str_trunc(abstract_fr, 100, ellipsis = "..."),
         abstract_en = str_trunc(abstract_en, 100, ellipsis = "..."))

DT::datatable(
  documents,
  extensions = 'Buttons',
  options = list(
    dom = 'Blfrtip',
    buttons = c('excel', 'csv'),
    pageLength = 3
  )
)

```

### Auteur.es 

```{r}
#| echo: TRUE
#| warning: FALSE
#| tbl-cap: "Table des auteurs"

authors_nested <- authors %>% 
  group_by(id_authors) %>% 
  mutate(id_document = list(id_document),
         institution = list(institution),
         year = list(year)) %>% 
  select(-"Type d'institution", -"Discipline 1", -"Discipline 2") %>%
  unique() 

DT::datatable(
  authors_nested,
  extensions = 'Buttons',
  options = list(
    dom = 'Blfrtip',
    buttons = c('excel', 'csv'),
    pageLength = 3
  )
)

```

### Editeur.es 


```{r}
#| echo: TRUE 
#| warning: FALSE
#| label: tbl-editors
#| tbl-cap: "Table des éditeurs"

DT::datatable(
  editors,
  extensions = 'Buttons',
  options = list(
    dom = 'Blfrtip',
    buttons = c('excel', 'csv'),
    pageLength = 3
  )
)

```








::: 
